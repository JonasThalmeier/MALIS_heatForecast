-- Baseline:
       def __init__(self, input_size):
        super(HotDayPredictor, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

Normaliaztion with global (trainig) mean and std.

Training Loss: 0.023145
Validation Loss: 1.825566
Training Loss Decreasing, Validation Loss Stagnating/Increasing -> Overfitting



-- Iteration 1:
Added Dropouts:
self.fc = nn.Sequential(
    nn.Linear(input_size, 128),
    nn.ReLU(),
    nn.Dropout(0.3),  # Add dropout with a rate of 30%
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Dropout(0.3),  # Add dropout
    nn.Linear(64, 1)
)

Added weighted loss function:
global_pos_weight = (global_total_count - global_positive_count) / global_positive_count
loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(global_pos_weight, dtype=torch.float32))

Lowered learning rate by factor 10 to 0.0001

Training Loss: 0.311259
Validation Loss: 20.156125

Stagneting training and val loss

-- Iteration 2
Added longitudes, latiduted and 95th percentile temp to records.
Still super high decrepancy between train and val loss. Val loss rises --> still overfitting
Training Loss: 0.299057
Validation Loss: 24.856614

-- Iteration 3
Generated an additional dataset with more variables and only the summer month.

No improvement. Still strong Overfitting
Training Loss: 0.282310
Validation Loss: 22.825080

With only land areas selected, the overfitting is even worse:
Training Loss: 0.161386
Validation Loss: 31.200668

Evaluation Metrics:
Accuracy: 0.8951
Precision: 0.1166
Recall: 0.0436
F1 Score: 0.0635


-- Iteration 4
Replace NN with random forest. Without balanced class weights, Acurracy=91% but Precision=Recall=0%
With balanced weights:
Random Forest Performance:
Accuracy: 0.9119
Precision: 0.2318
Recall: 0.0347
F1 Score: 0.0604

With class_weight={0: 1, 1: 68}:
Random Forest Performance:
Accuracy: 0.9106
Precision: 0.1973
Recall: 0.0315
F1 Score: 0.0544

-- Iteration V
XGBClassifier with scale_pos_wheight=len(y_train_rf[y_train_rf == 0]) / len(y_train_rf[y_train_rf == 1]) . Still low F1 Score
Accuracy: 0.9185
Precision: 0.5106
Recall: 0.0010
F1 Score: 0.0021

Wehn the percentile is changed to 85%:
Accuracy: 0.7754
Precision: 0.6416
Recall: 0.0840
F1 Score: 0.1486

With logistic regression better results (95 percentile). (lbfgs solver, 500 iterations)
Accuracy: 0.8164
Precision: 0.1632
Recall: 0.3033
F1 Score: 0.2122

-- Iteration VI
torch LogisticRegressionModel. Less Overfitting, but still poor F1
Logistic Regression Performance (PyTorch):
Accuracy: 0.9037
Precision: 0.1459
Recall: 0.0077
F1 Score: 0.0146

-- Iteration VII
Same model as before but with weights
added: criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([positive_weight], dtype=torch.float32))
Results are better but still worse than with sklearn
Accuracy: 0.7819
Precision: 0.1026
Recall: 0.1741
F1 Score: 0.1291



