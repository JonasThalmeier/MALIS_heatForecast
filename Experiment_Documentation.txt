-- Baseline:
       def __init__(self, input_size):
        super(HotDayPredictor, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

Normaliaztion with global (trainig) mean and std.

Training Loss: 0.023145
Validation Loss: 1.825566
Training Loss Decreasing, Validation Loss Stagnating/Increasing -> Overfitting



-- Iteration 1:
Added Dropouts:
self.fc = nn.Sequential(
    nn.Linear(input_size, 128),
    nn.ReLU(),
    nn.Dropout(0.3),  # Add dropout with a rate of 30%
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Dropout(0.3),  # Add dropout
    nn.Linear(64, 1)
)

Added weighted loss function:
global_pos_weight = (global_total_count - global_positive_count) / global_positive_count
loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(global_pos_weight, dtype=torch.float32))

Lowered learning rate by factor 10 to 0.0001

Training Loss: 0.311259
Validation Loss: 20.156125

Stagneting training and val loss

-- Iteration 2
Added longitudes, latiduted and 95th percentile temp to records.
Still super high decrepancy between train and val loss. Val loss rises --> still overfitting
Training Loss: 0.299057
Validation Loss: 24.856614

-- Iteration 3
Generated an additional dataset with more variables and only the summer month.

No improvement. Still strong Overfitting
Training Loss: 0.282310
Validation Loss: 22.825080

With only land areas selected, the overfitting is even worse:
Training Loss: 0.161386
Validation Loss: 31.200668
