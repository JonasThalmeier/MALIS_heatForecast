{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59dbbb72",
   "metadata": {},
   "source": [
    "## Initial Steps for Working with GRIB Dataset in Python\n",
    "\n",
    "### Step 1: Install Required Libraries\n",
    "You will need pygrib, xarray, numpy, pandas, and matplotlib.\n",
    "Use the following command to install them:\n",
    "!pip install pygrib xarray numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa56588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6e25",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the GRIB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da6b88b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping variable: paramId==235033 shortName='avg_ishf'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1143849600, 1143892800, 1143936000, ..., 1727611200, 1727654400,\n",
      "       1727697600])) new_value=Variable(dimensions=('time',), data=array([1143828000, 1143871200, 1143914400, ..., 1727589600, 1727632800,\n",
      "       1727676000]))\n",
      "skipping variable: paramId==147 shortName='slhf'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1143849600, 1143892800, 1143936000, ..., 1727611200, 1727654400,\n",
      "       1727697600])) new_value=Variable(dimensions=('time',), data=array([1143828000, 1143871200, 1143914400, ..., 1727589600, 1727632800,\n",
      "       1727676000]))\n",
      "skipping variable: paramId==169 shortName='ssrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1143849600, 1143892800, 1143936000, ..., 1727611200, 1727654400,\n",
      "       1727697600])) new_value=Variable(dimensions=('time',), data=array([1143828000, 1143871200, 1143914400, ..., 1727589600, 1727632800,\n",
      "       1727676000]))\n",
      "skipping variable: paramId==212 shortName='tisr'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1143849600, 1143892800, 1143936000, ..., 1727611200, 1727654400,\n",
      "       1727697600])) new_value=Variable(dimensions=('time',), data=array([1143828000, 1143871200, 1143914400, ..., 1727589600, 1727632800,\n",
      "       1727676000]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of the dataset:\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "  * time                 (time) datetime64[ns] 56kB 2006-04-01 ... 2024-09-30...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    valid_time           (time) datetime64[ns] 56kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "\n",
      "Latitude values:\n",
      "[44.   43.75 43.5  43.25 43.   42.75 42.5  42.25 42.   41.75 41.5  41.25\n",
      " 41.   40.75 40.5  40.25 40.   39.75 39.5  39.25 39.   38.75 38.5  38.25\n",
      " 38.   37.75 37.5  37.25 37.   36.75 36.5  36.25 36.  ]\n",
      "\n",
      "Longitude values:\n",
      "[-10.    -9.75  -9.5   -9.25  -9.    -8.75  -8.5   -8.25  -8.    -7.75\n",
      "  -7.5   -7.25  -7.    -6.75  -6.5   -6.25  -6.    -5.75  -5.5   -5.25\n",
      "  -5.    -4.75  -4.5   -4.25  -4.    -3.75  -3.5   -3.25  -3.    -2.75\n",
      "  -2.5   -2.25  -2.    -1.75  -1.5   -1.25  -1.    -0.75  -0.5   -0.25\n",
      "   0.     0.25   0.5    0.75   1.     1.25   1.5    1.75   2.     2.25\n",
      "   2.5    2.75   3.     3.25   3.5    3.75   4.  ]\n",
      "\n",
      "Time values:\n",
      "['2006-04-01T00:00:00.000000000' '2006-04-01T12:00:00.000000000'\n",
      " '2006-04-02T00:00:00.000000000' ... '2024-09-29T12:00:00.000000000'\n",
      " '2024-09-30T00:00:00.000000000' '2024-09-30T12:00:00.000000000']\n",
      "Data variables:\n",
      "    u10      (time, latitude, longitude) float32 52MB ...\n",
      "    v10      (time, latitude, longitude) float32 52MB ...\n",
      "    d2m      (time, latitude, longitude) float32 52MB ...\n",
      "    t2m      (time, latitude, longitude) float32 52MB ...\n",
      "    msl      (time, latitude, longitude) float32 52MB ...\n",
      "    sp       (time, latitude, longitude) float32 52MB ...\n",
      "    skt      (time, latitude, longitude) float32 52MB ...\n",
      "    tcc      (time, latitude, longitude) float32 52MB ...\n",
      "    swvl1    (time, latitude, longitude) float32 52MB ...\n",
      "    blh      (time, latitude, longitude) float32 52MB ...\n",
      "    lsm      (time, latitude, longitude) float32 52MB ...\n",
      "    tcwv     (time, latitude, longitude) float32 52MB ...\n"
     ]
    }
   ],
   "source": [
    "# Load the GRIB dataset\n",
    "data = xr.open_dataset('./spain_may2sept.grib', engine=\"cfgrib\")\n",
    "\n",
    "# Print available coordinates\n",
    "print(\"Coordinates of the dataset:\")\n",
    "print(data.coords)\n",
    "\n",
    "# Optionally, print specific coordinate values\n",
    "print(\"\\nLatitude values:\")\n",
    "print(data[\"latitude\"].values)\n",
    "\n",
    "print(\"\\nLongitude values:\")\n",
    "print(data[\"longitude\"].values)\n",
    "\n",
    "# If the dataset has time:\n",
    "if \"time\" in data.coords:\n",
    "    print(\"\\nTime values:\")\n",
    "    print(data[\"time\"].values)\n",
    "    \n",
    "print(data.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a7ef5",
   "metadata": {},
   "source": [
    "## Generate labels for hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe8173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_region = data.sel(\n",
    "    latitude=slice(43, 38),  # From 43°N to 38°N (descending order)\n",
    "    longitude=slice(-8, -1)  # From 8°W to 1°W (ascending order)\n",
    ")\n",
    "# Step 1: Restrict the dataset to May–August\n",
    "data_summer = data_region.sel(time=data[\"time\"].dt.month.isin([5, 6, 7, 8, 9]))\n",
    "\n",
    "# Step 2: Extract temperature data (e.g., variable \"t2m\") for the summer months\n",
    "temperature_summer = data_summer[\"t2m\"]\n",
    "# Step 3: Filter temperature measurements at 12:00 within summer months\n",
    "# Step 3: Filter temperature measurements at 12:00 within summer months\n",
    "temp_summer_12 = temperature_summer.sel(time=temperature_summer[\"time\"].dt.hour == 12)\n",
    "\n",
    "# Convert the time to \"day\" in datetime format with time set to 00:00:00\n",
    "temp_summer_12 = temp_summer_12.assign_coords(day=temp_summer_12[\"time\"].dt.floor(\"D\"))\n",
    "\n",
    "# Use \"day\" as the main dimension\n",
    "temp_summer_12 = temp_summer_12.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "\n",
    "# Step 4: Extract July–August temperatures for percentile calculation\n",
    "temp_july_aug = temp_summer_12.sel(day=temp_summer_12[\"day\"].dt.month.isin([7, 8]))\n",
    "\n",
    "\n",
    "# Step 5: Compute the 95th percentile for each location in July–August\n",
    "\n",
    "###\n",
    "percentile_95 = temp_july_aug.quantile(0.70, dim=\"day\")\n",
    "###\n",
    "\n",
    "# Step 6: Label hot days (May–August) based on the 95th percentile\n",
    "hot_days = temp_summer_12 > percentile_95\n",
    "\n",
    "# Step 7: Add the \"hot_day\" label to the summer dataset\n",
    "data_summer_labeled = data_summer.assign(hot_day=hot_days)\n",
    "\n",
    "# Optional: Save the labeled dataset for further analysis\n",
    "# data_summer_labeled.to_netcdf(\"labeled_summer_dataset.nc\")\n",
    "\n",
    "# Step 8: Verify the results\n",
    "# print(\"Summer Dataset with Hot Day Labels:\")\n",
    "# print(data_summer_labeled.where(data_summer_labeled[\"hot_day\"], drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd0f9e",
   "metadata": {},
   "source": [
    "## Aggregate all measurements of one day under one timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summer_00 = data_summer.sel(time=data_summer[\"time\"].dt.hour == 0)\n",
    "data_summer_12 = data_summer.sel(time=data_summer[\"time\"].dt.hour == 12)\n",
    "\n",
    "data_summer_00 = data_summer_00.assign_coords(day=data_summer_00[\"time\"].dt.floor(\"D\"))\n",
    "data_summer_12 = data_summer_12.assign_coords(day=data_summer_12[\"time\"].dt.floor(\"D\"))\n",
    "\n",
    "data_summer_00 = data_summer_00.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "data_summer_12 = data_summer_12.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "\n",
    "\n",
    "# Rename variables in each dataset to include their time suffix\n",
    "data_summer_00 = data_summer_00.rename({var: f\"{var}_00\" for var in data_summer_00.data_vars})\n",
    "data_summer_12 = data_summer_12.rename({var: f\"{var}_12\" for var in data_summer_12.data_vars})\n",
    "data_summer_00 = data_summer_00.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "data_summer_12 = data_summer_12.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "\n",
    "# Merge the renamed datasets\n",
    "data_summer_merged = xr.merge([data_summer_00, data_summer_12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf158da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th Percentile Temperature Values:\n",
      "<xarray.DataArray 't2m' (latitude: 21, longitude: 29)> Size: 5kB\n",
      "array([[27.5572876 , 27.87758789, 27.97233887, 28.19266357, 27.68026123,\n",
      "        27.32561035, 26.5927002 , 26.18048096, 25.74979248, 26.54486084,\n",
      "        27.04223633, 27.00927734, 26.13225098, 26.30419922, 26.8317627 ,\n",
      "        28.80769043, 29.26304932, 29.04807129, 30.08210449, 30.35366211,\n",
      "        30.30133057, 30.58551025, 29.90827637, 29.87215576, 29.4390625 ,\n",
      "        29.8085083 , 30.48804932, 30.46975098, 29.27783203],\n",
      "       [28.48967285, 28.87312012, 29.31704102, 28.87319336, 28.87126465,\n",
      "        28.95294189, 28.75070801, 28.32772217, 28.17265625, 29.48787842,\n",
      "        30.04727783, 29.56262207, 28.8020752 , 28.99291992, 29.43897705,\n",
      "        30.58569336, 30.51279297, 30.67890625, 31.7723877 , 31.82441406,\n",
      "        31.68465576, 31.40041504, 31.4696167 , 31.14534912, 31.63909912,\n",
      "        31.99084473, 31.91234131, 31.39389648, 30.24213867],\n",
      "       [29.38776855, 29.41948242, 29.22969971, 29.4793335 , 29.34759521,\n",
      "        29.94361572, 30.12387695, 30.57890625, 31.27611084, 32.09641113,\n",
      "        32.40467529, 31.59237061, 31.38636475, 31.44472656, 31.5529541 ,\n",
      "        31.68360596, 31.76987305, 31.76456299, 31.95712891, 31.42774658,\n",
      "        31.78088379, 32.18311768, 33.18787842, 33.22044678, 33.87720947,\n",
      "        34.48869629, 34.41676025, 34.03543701, 33.59329834],\n",
      "       [30.03302002, 30.23029785, 29.49697266, 28.87702637, 28.3432251 ,\n",
      "        28.32607422, 29.08348389, 30.25700684, 32.17010498, 32.83925781,\n",
      "...\n",
      "        36.33648682, 35.849646  , 35.28487549, 35.58018799, 35.93261719,\n",
      "        35.81590576, 35.096521  , 35.09049072, 35.58344727],\n",
      "       [36.20870361, 36.52403564, 37.00638428, 36.98458252, 36.74093018,\n",
      "        36.96807861, 36.44143066, 36.26185303, 36.29599609, 36.27921143,\n",
      "        36.30516357, 36.75904541, 36.93302002, 36.84932861, 36.9559082 ,\n",
      "        36.48806152, 36.8918457 , 37.24793701, 37.12515869, 37.22198486,\n",
      "        36.9984375 , 36.48895264, 35.359375  , 35.28103027, 35.65638428,\n",
      "        36.71964111, 36.16424561, 36.16942139, 35.52717285],\n",
      "       [36.02780762, 36.38133545, 36.97333984, 37.00787354, 36.69741211,\n",
      "        36.13415527, 35.62978516, 35.53341064, 35.88415527, 36.11270752,\n",
      "        36.09483643, 36.53414307, 36.48820801, 36.95915527, 37.43879395,\n",
      "        37.23751221, 37.77686768, 37.97943115, 37.91964111, 38.24362793,\n",
      "        37.03043213, 35.38743896, 34.19633789, 34.53768311, 35.60783691,\n",
      "        36.9190918 , 36.68348389, 36.71345215, 36.69344482],\n",
      "       [35.71236572, 36.05302734, 36.28117676, 36.55151367, 36.65266113,\n",
      "        36.0427002 , 35.80253906, 35.94898682, 36.25477295, 36.44935303,\n",
      "        36.74534912, 36.7850708 , 37.0050415 , 37.51147461, 38.36795654,\n",
      "        38.35799561, 38.68227539, 38.87113037, 38.53684082, 37.50806885,\n",
      "        36.18182373, 34.20645752, 33.50466309, 33.58037109, 34.715625  ,\n",
      "        35.99592285, 36.34423828, 36.95644531, 37.09134521]])\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 168B 43.0 42.75 42.5 42.25 ... 38.5 38.25 38.0\n",
      "  * longitude  (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.5 -1.25 -1.0\n",
      "    quantile   float64 8B 0.95\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the percentile with a lower threshold\n",
    "percentile_95 = temp_july_aug.quantile(0.95, dim=\"day\")\n",
    "print(\"95th Percentile Temperature Values:\")\n",
    "print(percentile_95-273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71db00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hot days: 272054\n",
      "Total number of days: 2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20464/988324806.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  num_days = data_summer_labeled.dims[\"day\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 3540726\n"
     ]
    }
   ],
   "source": [
    "# Count the number of hot days (True values) in the \"hot_day\" field\n",
    "num_hot_days = data_summer_labeled[\"hot_day\"].sum().item()\n",
    "\n",
    "print(f\"Total number of hot days: {num_hot_days}\")\n",
    "\n",
    "# Count the number of hot days (True values) in the \"hot_day\" field\n",
    "num_days = data_summer_labeled.dims[\"day\"]\n",
    "print(f\"Total number of days: {num_days}\")\n",
    "\n",
    "# Sum the count of non-NaN values in \"t2m\" across time, latitude, and longitude\n",
    "num_data_points = data_summer_labeled[\"t2m\"].notnull().sum().item()\n",
    "print(f\"Total number of data points: {num_data_points}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01354fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp Summer Dimensions: (2907, 21, 29)\n",
      "Percentile 95 Shape: (21, 29)\n",
      "Hot Days Shape: (2907, 21, 29)\n",
      "Variable names: ['u10', 'v10', 'd2m', 't2m', 'msl', 'sp', 'skt', 'tcc', 'swvl1', 'blh', 'lsm', 'tcwv']\n"
     ]
    }
   ],
   "source": [
    "print(\"Temp Summer Dimensions:\", temp_summer_12.shape)\n",
    "print(\"Percentile 95 Shape:\", percentile_95.shape)\n",
    "print(\"Hot Days Shape:\", hot_days.shape)\n",
    "variable_names = list(data.data_vars)\n",
    "print(\"Variable names:\", variable_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a69a5",
   "metadata": {},
   "source": [
    "## Calculating the number of 3 day streaks for each location to check if labeling is plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f72fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Three-Day Streaks per Location:\n",
      "<xarray.DataArray 't2m' (latitude: 21, longitude: 29)> Size: 5kB\n",
      "array([[142, 139, 141, 135, 131, 120, 122, 122, 119, 117, 120, 120, 115,\n",
      "        119, 121, 124, 136, 129, 132, 138, 138, 135, 136, 134, 128, 121,\n",
      "        122, 120, 120],\n",
      "       [139, 139, 135, 126, 126, 124, 106, 102, 106, 103, 101,  99, 100,\n",
      "        103, 107, 114, 115, 120, 120, 126, 129, 123, 116, 117, 112, 105,\n",
      "        107, 105, 104],\n",
      "       [136, 133, 127, 122, 123, 112, 105,  99,  98, 102, 103, 101, 102,\n",
      "        104, 105, 105, 106, 106, 104, 107, 114, 106, 105, 105,  97, 101,\n",
      "        101,  94,  89],\n",
      "       [128, 124, 123, 117, 109, 105, 103,  99,  93, 100, 107, 108, 105,\n",
      "        103, 103, 103, 108, 100, 102, 105, 102, 103, 103, 103, 101, 102,\n",
      "        103,  98,  87],\n",
      "       [117, 117, 113, 105,  94, 101, 100,  95, 101, 109, 109, 110, 111,\n",
      "        110, 109, 108, 107,  96,  96,  96,  96,  97, 100, 105, 101, 107,\n",
      "         98, 102,  98],\n",
      "       [114, 107,  98,  98, 101, 105, 100,  94, 101, 107, 111, 111, 111,\n",
      "        114, 112, 107, 103,  96,  95, 100,  98,  97,  97, 105, 107, 105,\n",
      "        100,  98,  98],\n",
      "       [112, 101,  97, 107, 109, 103, 101, 103, 112, 115, 113, 111, 107,\n",
      "        100, 104, 105, 100,  96,  91,  87,  93,  98,  99, 106, 106, 107,\n",
      "...\n",
      "         95,  98,  90,  86,  86,  88,  88,  89,  84,  79,  83,  84,  86,\n",
      "         91,  92,  91],\n",
      "       [125, 116, 110, 108, 104, 108, 104, 105, 100, 100, 100,  99, 101,\n",
      "         99,  96,  94,  93,  92,  86,  89,  89,  81,  81,  84,  80,  84,\n",
      "         88,  94,  95],\n",
      "       [127, 116, 109, 107, 106, 110, 105, 102, 109, 102, 103, 101,  98,\n",
      "         98,  96,  93,  92,  90,  89,  88,  81,  80,  73,  79,  82,  82,\n",
      "         84,  86,  92],\n",
      "       [124, 113, 106, 110, 109, 109, 108, 105, 106, 103, 104, 104,  98,\n",
      "         95,  94,  88,  93,  94,  83,  82,  77,  81,  76,  76,  84,  87,\n",
      "         84,  85,  90],\n",
      "       [121, 112, 110, 110, 114, 108, 101, 102, 103,  98, 100,  99,  97,\n",
      "         93,  93,  93,  91,  90,  88,  86,  79,  81,  77,  84,  86,  90,\n",
      "         87,  88,  89],\n",
      "       [125, 117, 115, 111, 108,  98,  96,  98, 101,  99,  93,  95,  97,\n",
      "         91,  87,  89,  90,  89,  89,  91,  83,  79,  74,  78,  89,  93,\n",
      "         87,  93,  96],\n",
      "       [132, 123, 121, 112, 106, 102,  97,  92,  93,  91,  94,  93,  95,\n",
      "        101,  98,  99,  93,  91,  93,  88,  77,  71,  73,  75,  93,  93,\n",
      "         87,  86,  94]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 168B 43.0 42.75 42.5 ... 38.25 38.0\n",
      "  * longitude            (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.25 -1.0\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "    quantile             float64 8B 0.7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deleting variables to free memory\n",
    "del data, data_region, data_summer, temperature_summer, temp_summer_12, temp_july_aug, data_summer_labeled, data_summer_00, data_summer_12\n",
    "\n",
    "\n",
    "# Step 1: Verify hot days array (already computed)\n",
    "# print(\"Hot Days Array (Summary):\")\n",
    "# print(hot_days)\n",
    "\n",
    "# Step 2: Apply a rolling window to compute streaks\n",
    "streaks_rolling = (\n",
    "    hot_days.rolling(day=2, center=False)   # Rolling 3-day window !!!!change back to 3!!!!!!!\n",
    "    .construct(\"window_dim\")                # Create a dimension for the rolling window\n",
    "    .reduce(np.all, dim=\"window_dim\")       # Check if all values in the window are True\n",
    ")\n",
    "\n",
    "# Step 3: Replace NaN values (from rolling) with 0\n",
    "streaks_rolling_filled = streaks_rolling.fillna(0).astype(int)\n",
    "\n",
    "# Verify rolling streaks\n",
    "# print(\"Rolling Streaks (3-Day):\")\n",
    "# print(streaks_rolling_filled)\n",
    "\n",
    "# Step 4: Count the number of streaks per location\n",
    "def count_distinct_streaks(array):\n",
    "    diff = np.diff(array, axis=0)\n",
    "    streak_starts = (diff == 1).sum(axis=0)  # Count where a streak begins\n",
    "    return streak_starts\n",
    "\n",
    "distinct_streaks = xr.apply_ufunc(\n",
    "    count_distinct_streaks,\n",
    "    streaks_rolling_filled,\n",
    "    input_core_dims=[[\"day\"]],\n",
    "    vectorize=True\n",
    ")\n",
    "\n",
    "# Step 5: Print results\n",
    "print(\"Distinct Three-Day Streaks per Location:\")\n",
    "print(distinct_streaks)\n",
    "\n",
    "# Optional: Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Distinct 3-Day Hot Streaks per Location\")\n",
    "plt.imshow(distinct_streaks, origin=\"lower\", aspect=\"auto\")\n",
    "plt.colorbar(label=\"Number of Streaks\")\n",
    "plt.xlabel(\"Longitude Index\")\n",
    "plt.ylabel(\"Latitude Index\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b831cef",
   "metadata": {},
   "source": [
    "## Creating Target labels for each day (if the next 7 days contain at least 3 hot days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21e6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling sum of hot days over 7-day window:\n",
      "<xarray.DataArray 't2m' (day: 2907, latitude: 21, longitude: 29)> Size: 14MB\n",
      "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=object)\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 168B 43.0 42.75 42.5 ... 38.25 38.0\n",
      "  * longitude            (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.25 -1.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n",
      "    quantile             float64 8B 0.7\n",
      "Labels before shifting (aligned with future interval):\n",
      "<xarray.DataArray 't2m' (day: 2907, latitude: 21, longitude: 29)> Size: 14MB\n",
      "array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 168B 43.0 42.75 42.5 ... 38.25 38.0\n",
      "  * longitude            (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.25 -1.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n",
      "    quantile             float64 8B 0.7\n",
      "Labels after shifting (aligned with current day):\n",
      "<xarray.DataArray 't2m' (day: 2905, latitude: 21, longitude: 29)> Size: 14MB\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 168B 43.0 42.75 42.5 ... 38.25 38.0\n",
      "  * longitude            (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.25 -1.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-28\n",
      "    quantile             float64 8B 0.7\n"
     ]
    }
   ],
   "source": [
    "# Define the rolling window size\n",
    "window_size = 3 #change back to 7!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# Step 1: Restrict hot_days to May–July + first days of August\n",
    "hot_days_limited = hot_days.sel(\n",
    "    day=hot_days[\"day\"].dt.month.isin([5, 6, 7]) |\n",
    "         ((hot_days[\"day\"].dt.month == 8) & (hot_days[\"day\"].dt.day <= window_size))\n",
    ")\n",
    "\n",
    "# Count the number of hot days in each rolling window\n",
    "hot_days_rolling = (\n",
    "    hot_days.rolling(day=window_size, center=False)\n",
    "    .construct(\"window_dim\")\n",
    "    .reduce(np.sum, dim=\"window_dim\")\n",
    ")\n",
    "\n",
    "# Create labels: 1 if 3 or more hot days, 0 otherwise\n",
    "labels_next_7_days = (hot_days_rolling >= 2).astype(int) #change back to 3!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# Align the labels with the dataset (shift back by window_size - 1)\n",
    "labels_next_7_days = labels_next_7_days.shift(day=-(window_size - 1))\n",
    "# Does this makes sense?????\n",
    "\n",
    "# Drop NaN values (caused by shifting)\n",
    "labels_next_7_days = labels_next_7_days.dropna(\"day\")\n",
    "\n",
    "# Debug: Inspect the rolling sum\n",
    "print(\"Rolling sum of hot days over 7-day window:\")\n",
    "print(hot_days_rolling)\n",
    "\n",
    "# Debug: Inspect the labels before and after shifting\n",
    "print(\"Labels before shifting (aligned with future interval):\")\n",
    "print((hot_days_rolling >= 2).astype(int)) #change back to 3!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "print(\"Labels after shifting (aligned with current day):\")\n",
    "print(labels_next_7_days)\n",
    "\n",
    "del hot_days, streaks_rolling, streaks_rolling_filled, distinct_streaks, hot_days_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861239fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable            Type                \n",
      "========================================\n",
      "percentile_95       DataArray           \n",
      "data_summer_merged  Dataset             \n",
      "hot_days_rolling    DataArray           \n",
      "labels_next_7_days  DataArray           \n",
      "                    types |   # objects |   total size\n",
      "========================= | =========== | ============\n",
      "                    tuple |      293635 |     28.13 MB\n",
      "                      str |      113505 |     20.43 MB\n",
      "                     dict |       36207 |     16.08 MB\n",
      "            numpy.ndarray |         283 |     14.21 MB\n",
      "                     list |       92799 |      9.70 MB\n",
      "                     code |       38709 |      6.61 MB\n",
      "                      int |      217727 |      6.16 MB\n",
      "                     type |        4905 |      4.48 MB\n",
      "                      set |        1138 |    768.55 KB\n",
      "  collections.OrderedDict |         493 |    509.59 KB\n",
      "    weakref.ReferenceType |        6720 |    472.50 KB\n",
      "              abc.ABCMeta |         407 |    417.51 KB\n",
      "                     cell |        9734 |    380.23 KB\n",
      "      function (__init__) |        2411 |    339.05 KB\n",
      "        inspect.Parameter |        4945 |    309.06 KB\n"
     ]
    }
   ],
   "source": [
    "from pympler import muppy, summary\n",
    "# Filter global variables for numpy arrays and xarray datasets\n",
    "arrays_and_datasets = {\n",
    "    name: type(value).__name__\n",
    "    for name, value in globals().items()\n",
    "    if type(value).__name__ in [\"ndarray\", \"Dataset\", \"DataArray\"]\n",
    "}\n",
    "\n",
    "# Print the results\n",
    "print(f\"{'Variable':<20}{'Type':<20}\")\n",
    "print(\"=\" * 40)\n",
    "for name, var_type in arrays_and_datasets.items():\n",
    "    print(f\"{name:<20}{var_type:<20}\")\n",
    "\n",
    "# Collect all objects in memory\n",
    "all_objects = muppy.get_objects()\n",
    "\n",
    "# Summarize memory usage by type\n",
    "summary.print_(summary.summarize(all_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0125e",
   "metadata": {},
   "source": [
    "## Stacking data of 30 days onto each other and adding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8305e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates:\n",
      "    number               int64 8B 0\n",
      "    step                 timedelta64[ns] 8B 00:00:00\n",
      "    surface              float64 8B 0.0\n",
      "  * latitude             (latitude) float64 168B 43.0 42.75 42.5 ... 38.25 38.0\n",
      "  * longitude            (longitude) float64 232B -8.0 -7.75 -7.5 ... -1.25 -1.0\n",
      "    depthBelowLandLayer  float64 8B 0.0\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n"
     ]
    }
   ],
   "source": [
    "print(data_summer_merged.coords)\n",
    "#print(\"Rolling Chunk Days:\")\n",
    "#print(rolling_chunk[\"day\"].values)\n",
    "\n",
    "#print(\"\\nLabels Next 7 Days:\")\n",
    "#print(labels_next_7_days[\"day\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f228d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flattened features (X_train): (57246, 723)\n",
      "Shape of flattened labels (y_train): (57246,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Extract unique years from the 'day' coordinate\n",
    "years = np.unique(data_summer_merged[\"day\"].dt.year)\n",
    "feature_window_size = 30\n",
    "percentile_95_stacked = percentile_95.stack(location=(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Directory for saving temporary results\n",
    "processed_dir = \"temp_features_by_year\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    # Select data for the current year\n",
    "    yearly_data = data_summer_merged.sel(\n",
    "            day=(data_summer_merged[\"day\"].dt.year == year) &\n",
    "                 (data_summer_merged[\"day\"].dt.month.isin([5, 6, 7, 8]))\n",
    "    )\n",
    "    # Create rolling windows\n",
    "    rolling_chunk = (\n",
    "        yearly_data.rolling(day=feature_window_size, center=False)\n",
    "        .construct(\"feature_dim\")\n",
    "        .dropna(\"day\")\n",
    "    )\n",
    "    \n",
    "    # Align features with labels\n",
    "    yearly_labels = labels_next_7_days.sel(day=rolling_chunk[\"day\"])\n",
    "    rolling_chunk, yearly_labels = xr.align(rolling_chunk, yearly_labels, join=\"inner\")\n",
    "\n",
    "    \n",
    "    stacked_features = rolling_chunk.stack(location=(\"latitude\", \"longitude\"))\n",
    "    flattened_features = stacked_features.to_array(dim=\"variables\").stack(features=(\"variables\", \"feature_dim\")).transpose(\"day\", \"location\", \"features\")\n",
    "    X = flattened_features.values.reshape(flattened_features.shape[0] * flattened_features.shape[1], -1)\n",
    "\n",
    "    # Extract latitude, longitude, and add percentile_95\n",
    "    latitudes = stacked_features[\"latitude\"].values\n",
    "    longitudes = stacked_features[\"longitude\"].values\n",
    "\n",
    "    # Add `percentile_95` to each location\n",
    "    percentile_95_values = percentile_95_stacked.sel(location=stacked_features[\"location\"]).values\n",
    "    repeated_percentile_95 = np.repeat(percentile_95_values, len(flattened_features[\"day\"]), axis=0)\n",
    "\n",
    "    # Repeat latitude and longitude for all records (days × locations)\n",
    "    repeated_latitudes = np.tile(latitudes, len(flattened_features[\"day\"]))\n",
    "    repeated_longitudes = np.tile(longitudes, len(flattened_features[\"day\"]))\n",
    "\n",
    "    # Concatenate latitude, longitude, and percentile_95 to the features\n",
    "    lat_long_percentile = np.column_stack([repeated_latitudes, repeated_longitudes, repeated_percentile_95])\n",
    "    X = np.hstack((X, lat_long_percentile))  # Add these features to the rolling features\n",
    "\n",
    "\n",
    "    # Check the resulting shape\n",
    "    #stacked_labels = yearly_labels.stack(location=(\"latitude\", \"longitude\"))\n",
    "    #flattened_labels = stacked_labels.to_array(dim=\"variables\").stack(features=(\"variables\", \"feature_dim\")).transpose(\"day\", \"location\", \"features\")\n",
    "    #aligned_labels = flattened_labels.sel(day=stacked_features[\"day\"])\n",
    "    #y = aligned_labels.values.flatten()  # Flatten into a single column\n",
    "    \n",
    "    stacked_labels = yearly_labels.stack(location=(\"latitude\", \"longitude\"))\n",
    "    y = stacked_labels.values.flatten()  # Flatten into a single column\n",
    "\n",
    "    # Save to disk\n",
    "    torch.save(torch.tensor(X, dtype=torch.float32), f\"{processed_dir}/features_{year}.pt\")\n",
    "    torch.save(torch.tensor(y, dtype=torch.float32), f\"{processed_dir}/labels_{year}.pt\")\n",
    "    \n",
    "print(\"Shape of flattened features (X_train):\", X.shape)\n",
    "print(\"Shape of flattened labels (y_train):\", y.shape)\n",
    "\n",
    "del data_summer_merged, hot_days_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ef4272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024.12.1\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "print(dask.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0b4af",
   "metadata": {},
   "source": [
    "## Train/Test split and flattening the arrays so they can be processed by NN\n",
    "The final array will be 2D. Each record corresponds with one location and one day. This record contains the data of the previous 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b29335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"temp_features_by_year\"\n",
    "\n",
    "# Load and train incrementally\n",
    "def load_data_for_year(year):\n",
    "    X = torch.load(f\"{processed_dir}/features_{year}.pt\")\n",
    "    y = torch.load(f\"{processed_dir}/labels_{year}.pt\")    \n",
    "    return X, y\n",
    "\n",
    "# Initialize DataLoader for incremental training\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b691acbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b6fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n",
      "torch.Size([57246])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data_for_year(2020)\n",
    "print(X_train.shape[1])\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "832fb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "years = np.linspace(2006,2024,24-6+1).astype(int)\n",
    "train_years = years[years < 2020]\n",
    "test_years = years[years >= 2020]\n",
    "\n",
    "# Train Random Forest on the entire training set\n",
    "X_train, y_train = [], []  # Collect all training data for Random Forest\n",
    "\n",
    "for year in train_years:\n",
    "    X_train_year, y_train_year = load_data_for_year(year)\n",
    "    X_train.append(X_train_year.numpy())  # Convert to numpy for sklearn\n",
    "    y_train.append(y_train_year.numpy())\n",
    "\n",
    "# Concatenate yearly data for Random Forest\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.hstack(y_train)\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "\n",
    "# Compute global mean and standard deviation from the full training set\n",
    "global_mean = np.mean(X_train, axis=0)\n",
    "global_std = np.std(X_train, axis=0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69116406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 63 epochs took 569 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, n_jobs=-1, random_state=42, solver=&#x27;saga&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=500, n_jobs=-1, random_state=42, solver=&#x27;saga&#x27;,\n",
       "                   verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, n_jobs=-1, random_state=42, solver='saga',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "lr_model = LogisticRegression(\n",
    "    penalty=\"l2\",  # Regularization\n",
    "    C=1.0,         # Regularization strength (1.0 is default)\n",
    "    # solver=\"lbfgs\", # Solver for large datasets\n",
    "    solver=\"saga\",\n",
    "    max_iter=500,  # Increase iterations for convergence\n",
    "    random_state=42,\n",
    "    verbose=1,  # Enable progress output\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3837287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8530\n",
      "Precision: 0.8131\n",
      "Recall: 0.6807\n",
      "F1 Score: 0.7411\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = [], []\n",
    "\n",
    "for year in test_years:\n",
    "    X_val_year, y_val_year = load_data_for_year(year)\n",
    "    X_test.append(X_val_year.numpy())\n",
    "    y_test.append(y_val_year.numpy())\n",
    "\n",
    "# Concatenate test data\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Predictions\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest\n",
    "accuracy = accuracy_score(y_test, lr_predictions)\n",
    "precision = precision_score(y_test, lr_predictions)\n",
    "recall = recall_score(y_test, lr_predictions)\n",
    "f1 = f1_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9a8f83f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20464/3238738054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Normalize test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_test_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_test_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalize_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "X_test, y_test = [], []\n",
    "for year in test_years:\n",
    "    X_val_year, y_val_year = load_data_for_year(year)\n",
    "    X_test.append(X_val_year.numpy())\n",
    "    y_test.append(y_val_year.numpy())\n",
    "\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "# Normalize test data\n",
    "X_test_torch = torch.tensor(normalize_features(torch.tensor(X_test), global_mean, global_std), dtype=torch.float32)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Predict\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_torch).squeeze()\n",
    "    predictions_binary = (predictions.numpy() > 0.5).astype(int)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, predictions_binary)\n",
    "precision = precision_score(y_test, predictions_binary)\n",
    "recall = recall_score(y_test, predictions_binary)\n",
    "f1 = f1_score(y_test, predictions_binary)\n",
    "\n",
    "print(\"\\nLogistic Regression Performance (PyTorch):\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_rf, return_counts=True)\n",
    "print(f\"Class distribution in training data: {dict(zip(unique, counts))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0170002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the plot\n",
    "fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# Plot training loss on the primary y-axis\n",
    "ax1.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\", color=\"blue\", marker=\"o\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Training Loss\", color=\"blue\")\n",
    "ax1.tick_params(axis='y', labelcolor=\"blue\")\n",
    "\n",
    "# Plot validation loss on the secondary y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", color=\"red\", marker=\"o\")\n",
    "ax2.set_ylabel(\"Validation Loss\", color=\"red\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Training and Validation Loss with Separate Y-Axes\")\n",
    "\n",
    "# Save the plot as a high-resolution PNG\n",
    "plt.savefig(\"training_validation_loss_Iteration4.png\", dpi=300, bbox_inches=\"tight\")  # 300 DPI for high resolution\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c0dab",
   "metadata": {},
   "source": [
    "### Using different NN and other models to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for year in test_years:\n",
    "    X_test, y_test = load_data_for_year(year)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Normalize features\n",
    "    X_test = (X_test - X_test.mean(dim=0)) / X_test.std(dim=0)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test).squeeze()\n",
    "        all_predictions.append((predictions > 0.5).float().numpy())\n",
    "        all_labels.append(y_test.numpy())\n",
    "\n",
    "# Combine results and evaluate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate = torch.sum(y_train == 1).item() / y_train.size(0)\n",
    "print(f\"Positive rate: {positive_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset and data loader\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class HotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = HotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Initial NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DeeperHotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DeeperHotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = DeeperHotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Deeper NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DropoutHotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DropoutHotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = DropoutHotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Dropout NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_classes = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "precision = precision_score(y_test, predicted_classes)\n",
    "recall = recall_score(y_test, predicted_classes)\n",
    "f1 = f1_score(y_test, predicted_classes)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.data_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
