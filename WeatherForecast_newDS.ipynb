{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59dbbb72",
   "metadata": {},
   "source": [
    "## Initial Steps for Working with GRIB Dataset in Python\n",
    "\n",
    "### Step 1: Install Required Libraries\n",
    "You will need pygrib, xarray, numpy, pandas, and matplotlib.\n",
    "Use the following command to install them:\n",
    "!pip install pygrib xarray numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa56588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6e25",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the GRIB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da6b88b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't read index file './data.grib.5b7b6.idx'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 550, in from_indexpath_or_filestream\n",
      "    self = cls.from_indexpath(indexpath)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/messages.py\", line 429, in from_indexpath\n",
      "    index = pickle.load(file)\n",
      "EOFError: Ran out of input\n",
      "skipping variable: paramId==228 shortName='tp'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1136073600, 1136116800, 1136160000, ..., 1732622400, 1732665600,\n",
      "       1732708800])) new_value=Variable(dimensions=('time',), data=array([1136052000, 1136095200, 1136138400, ..., 1732600800, 1732644000,\n",
      "       1732687200]))\n",
      "skipping variable: paramId==182 shortName='e'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
      "    dict_merge(variables, coord_vars)\n",
      "  File \"/home/jonas/.local/lib/python3.10/site-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
      "    raise DatasetBuildError(\n",
      "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='time' value=Variable(dimensions=('time',), data=array([1136073600, 1136116800, 1136160000, ..., 1732622400, 1732665600,\n",
      "       1732708800])) new_value=Variable(dimensions=('time',), data=array([1136052000, 1136095200, 1136138400, ..., 1732600800, 1732644000,\n",
      "       1732687200]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of the dataset:\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "  * time                 (time) datetime64[ns] 102kB 2006-01-01 ... 2024-11-2...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    valid_time           (time) datetime64[ns] 102kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "\n",
      "Latitude values:\n",
      "[44.   43.75 43.5  43.25 43.   42.75 42.5  42.25 42.   41.75 41.5  41.25\n",
      " 41.   40.75 40.5  40.25 40.   39.75 39.5  39.25 39.   38.75 38.5  38.25\n",
      " 38.   37.75 37.5  37.25 37.   36.75 36.5  36.25 36.  ]\n",
      "\n",
      "Longitude values:\n",
      "[-10.    -9.75  -9.5   -9.25  -9.    -8.75  -8.5   -8.25  -8.    -7.75\n",
      "  -7.5   -7.25  -7.    -6.75  -6.5   -6.25  -6.    -5.75  -5.5   -5.25\n",
      "  -5.    -4.75  -4.5   -4.25  -4.    -3.75  -3.5   -3.25  -3.    -2.75\n",
      "  -2.5   -2.25  -2.    -1.75  -1.5   -1.25  -1.    -0.75  -0.5   -0.25\n",
      "   0.     0.25   0.5    0.75   1.     1.25   1.5    1.75   2.     2.25\n",
      "   2.5    2.75   3.     3.25   3.5    3.75   4.  ]\n",
      "\n",
      "Time values:\n",
      "['2006-01-01T00:00:00.000000000' '2006-01-01T12:00:00.000000000'\n",
      " '2006-01-02T00:00:00.000000000' ... '2024-11-26T12:00:00.000000000'\n",
      " '2024-11-27T00:00:00.000000000' '2024-11-27T12:00:00.000000000']\n",
      "Data variables:\n",
      "    u10      (time, latitude, longitude) float32 96MB ...\n",
      "    v10      (time, latitude, longitude) float32 96MB ...\n",
      "    d2m      (time, latitude, longitude) float32 96MB ...\n",
      "    t2m      (time, latitude, longitude) float32 96MB ...\n",
      "    msl      (time, latitude, longitude) float32 96MB ...\n",
      "    tcc      (time, latitude, longitude) float32 96MB ...\n",
      "    swvl1    (time, latitude, longitude) float32 96MB ...\n"
     ]
    }
   ],
   "source": [
    "# Load the GRIB dataset\n",
    "data = xr.open_dataset('./data.grib', engine=\"cfgrib\")\n",
    "\n",
    "# Print available coordinates\n",
    "print(\"Coordinates of the dataset:\")\n",
    "print(data.coords)\n",
    "\n",
    "# Optionally, print specific coordinate values\n",
    "print(\"\\nLatitude values:\")\n",
    "print(data[\"latitude\"].values)\n",
    "\n",
    "print(\"\\nLongitude values:\")\n",
    "print(data[\"longitude\"].values)\n",
    "\n",
    "# If the dataset has time:\n",
    "if \"time\" in data.coords:\n",
    "    print(\"\\nTime values:\")\n",
    "    print(data[\"time\"].values)\n",
    "    \n",
    "print(data.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a7ef5",
   "metadata": {},
   "source": [
    "## Generate labels for hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fe8173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Restrict the dataset to May–August\n",
    "data_summer = data.sel(time=data[\"time\"].dt.month.isin([5, 6, 7, 8, 9]))\n",
    "\n",
    "# Step 2: Extract temperature data (e.g., variable \"t2m\") for the summer months\n",
    "temperature_summer = data_summer[\"t2m\"]\n",
    "# Step 3: Filter temperature measurements at 12:00 within summer months\n",
    "# Step 3: Filter temperature measurements at 12:00 within summer months\n",
    "temp_summer_12 = temperature_summer.sel(time=temperature_summer[\"time\"].dt.hour == 12)\n",
    "\n",
    "# Convert the time to \"day\" in datetime format with time set to 00:00:00\n",
    "temp_summer_12 = temp_summer_12.assign_coords(day=temp_summer_12[\"time\"].dt.floor(\"D\"))\n",
    "\n",
    "# Use \"day\" as the main dimension\n",
    "temp_summer_12 = temp_summer_12.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "\n",
    "# Step 4: Extract July–August temperatures for percentile calculation\n",
    "temp_july_aug = temp_summer_12.sel(day=temp_summer_12[\"day\"].dt.month.isin([7, 8]))\n",
    "\n",
    "\n",
    "# Step 5: Compute the 95th percentile for each location in July–August\n",
    "percentile_95 = temp_july_aug.quantile(0.95, dim=\"day\")\n",
    "\n",
    "# Step 6: Label hot days (May–August) based on the 95th percentile\n",
    "hot_days = temp_summer_12 > percentile_95\n",
    "\n",
    "# Step 7: Add the \"hot_day\" label to the summer dataset\n",
    "data_summer_labeled = data_summer.assign(hot_day=hot_days)\n",
    "\n",
    "# Optional: Save the labeled dataset for further analysis\n",
    "# data_summer_labeled.to_netcdf(\"labeled_summer_dataset.nc\")\n",
    "\n",
    "# Step 8: Verify the results\n",
    "# print(\"Summer Dataset with Hot Day Labels:\")\n",
    "# print(data_summer_labeled.where(data_summer_labeled[\"hot_day\"], drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd0f9e",
   "metadata": {},
   "source": [
    "## Aggregate all measurements of one day under one timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summer_00 = data_summer.sel(time=data_summer[\"time\"].dt.hour == 0)\n",
    "data_summer_12 = data_summer.sel(time=data_summer[\"time\"].dt.hour == 12)\n",
    "\n",
    "data_summer_00 = data_summer_00.assign_coords(day=data_summer_00[\"time\"].dt.floor(\"D\"))\n",
    "data_summer_12 = data_summer_12.assign_coords(day=data_summer_12[\"time\"].dt.floor(\"D\"))\n",
    "\n",
    "data_summer_00 = data_summer_00.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "data_summer_12 = data_summer_12.swap_dims({\"time\": \"day\"}).reset_coords(\"time\", drop=True)\n",
    "\n",
    "\n",
    "# Rename variables in each dataset to include their time suffix\n",
    "data_summer_00 = data_summer_00.rename({var: f\"{var}_00\" for var in data_summer_00.data_vars})\n",
    "data_summer_12 = data_summer_12.rename({var: f\"{var}_12\" for var in data_summer_12.data_vars})\n",
    "data_summer_00 = data_summer_00.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "data_summer_12 = data_summer_12.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "\n",
    "# Merge the renamed datasets\n",
    "data_summer_merged = xr.merge([data_summer_00, data_summer_12])\n",
    "# data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf158da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65th Percentile Temperature Values:\n",
      "<xarray.DataArray 't2m' (latitude: 33, longitude: 57)> Size: 15kB\n",
      "array([[20.33293457, 20.28775635, 20.31478271, ..., 30.69234619,\n",
      "        32.3020874 , 34.19785156],\n",
      "       [20.34399414, 20.30152588, 20.2145752 , ..., 33.10712891,\n",
      "        33.90869141, 34.67664795],\n",
      "       [20.18468018, 20.06081543, 19.94587402, ..., 30.93466797,\n",
      "        29.3979126 , 29.1164917 ],\n",
      "       ...,\n",
      "       [22.67811279, 22.6168457 , 22.70465088, ..., 38.96369629,\n",
      "        39.07728271, 39.13527832],\n",
      "       [22.76929932, 22.83873291, 22.96600342, ..., 38.54870605,\n",
      "        38.49307861, 38.82207031],\n",
      "       [22.81617432, 22.9895752 , 23.14813232, ..., 38.93109131,\n",
      "        39.0151001 , 39.23912354]])\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 264B 44.0 43.75 43.5 43.25 ... 36.5 36.25 36.0\n",
      "  * longitude  (longitude) float64 456B -10.0 -9.75 -9.5 -9.25 ... 3.5 3.75 4.0\n",
      "    quantile   float64 8B 0.95\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the percentile with a lower threshold\n",
    "percentile_95 = temp_july_aug.quantile(0.95, dim=\"day\")\n",
    "print(\"65th Percentile Temperature Values:\")\n",
    "print(percentile_95-273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71db00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hot days: 139463\n",
      "Total number of days: 2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16611/988324806.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  num_days = data_summer_labeled.dims[\"day\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points: 10936134\n"
     ]
    }
   ],
   "source": [
    "# Count the number of hot days (True values) in the \"hot_day\" field\n",
    "num_hot_days = data_summer_labeled[\"hot_day\"].sum().item()\n",
    "\n",
    "print(f\"Total number of hot days: {num_hot_days}\")\n",
    "\n",
    "# Count the number of hot days (True values) in the \"hot_day\" field\n",
    "num_days = data_summer_labeled.dims[\"day\"]\n",
    "print(f\"Total number of days: {num_days}\")\n",
    "\n",
    "# Sum the count of non-NaN values in \"t2m\" across time, latitude, and longitude\n",
    "num_data_points = data_summer_labeled[\"t2m\"].notnull().sum().item()\n",
    "print(f\"Total number of data points: {num_data_points}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01354fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp Summer Dimensions: (2907, 33, 57)\n",
      "Percentile 95 Shape: (33, 57)\n",
      "Hot Days Shape: (2907, 33, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"Temp Summer Dimensions:\", temp_summer_12.shape)\n",
    "print(\"Percentile 95 Shape:\", percentile_95.shape)\n",
    "print(\"Hot Days Shape:\", hot_days.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a69a5",
   "metadata": {},
   "source": [
    "## Calculating the number of 3 day streaks for each location to check if labeling is plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f72fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Three-Day Streaks per Location:\n",
      "<xarray.DataArray 't2m' (latitude: 33, longitude: 57)> Size: 15kB\n",
      "array([[ 9, 10,  9, ...,  9,  6,  9],\n",
      "       [ 9,  8,  7, ...,  8,  8,  8],\n",
      "       [ 8,  7,  6, ...,  7,  8,  9],\n",
      "       ...,\n",
      "       [12, 15, 15, ...,  7,  7,  6],\n",
      "       [12, 13, 13, ...,  6,  7,  7],\n",
      "       [15, 12, 13, ...,  7,  8,  6]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "    quantile             float64 8B 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deleting variables to free memory\n",
    "del data, data_summer, temperature_summer, temp_summer_12, temp_july_aug, percentile_95, data_summer_labeled, data_summer_00, data_summer_12\n",
    "\n",
    "\n",
    "# Step 1: Verify hot days array (already computed)\n",
    "# print(\"Hot Days Array (Summary):\")\n",
    "# print(hot_days)\n",
    "\n",
    "# Step 2: Apply a rolling window to compute streaks\n",
    "streaks_rolling = (\n",
    "    hot_days.rolling(day=3, center=False)   # Rolling 3-day window\n",
    "    .construct(\"window_dim\")                # Create a dimension for the rolling window\n",
    "    .reduce(np.all, dim=\"window_dim\")       # Check if all values in the window are True\n",
    ")\n",
    "\n",
    "# Step 3: Replace NaN values (from rolling) with 0\n",
    "streaks_rolling_filled = streaks_rolling.fillna(0).astype(int)\n",
    "\n",
    "# Verify rolling streaks\n",
    "# print(\"Rolling Streaks (3-Day):\")\n",
    "# print(streaks_rolling_filled)\n",
    "\n",
    "# Step 4: Count the number of streaks per location\n",
    "def count_distinct_streaks(array):\n",
    "    diff = np.diff(array, axis=0)\n",
    "    streak_starts = (diff == 1).sum(axis=0)  # Count where a streak begins\n",
    "    return streak_starts\n",
    "\n",
    "distinct_streaks = xr.apply_ufunc(\n",
    "    count_distinct_streaks,\n",
    "    streaks_rolling_filled,\n",
    "    input_core_dims=[[\"day\"]],\n",
    "    vectorize=True\n",
    ")\n",
    "\n",
    "# Step 5: Print results\n",
    "print(\"Distinct Three-Day Streaks per Location:\")\n",
    "print(distinct_streaks)\n",
    "\n",
    "# Optional: Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Distinct 3-Day Hot Streaks per Location\")\n",
    "plt.imshow(distinct_streaks, origin=\"lower\", aspect=\"auto\")\n",
    "plt.colorbar(label=\"Number of Streaks\")\n",
    "plt.xlabel(\"Longitude Index\")\n",
    "plt.ylabel(\"Latitude Index\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b831cef",
   "metadata": {},
   "source": [
    "## Creating Target labels for each day (if the next 7 days contain at least 3 hot days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c21e6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling sum of hot days over 7-day window:\n",
      "<xarray.DataArray 't2m' (day: 2907, latitude: 33, longitude: 57)> Size: 44MB\n",
      "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 0, ..., 0, 0, 0],\n",
      "        [1, 1, 0, ..., 0, 0, 0],\n",
      "        [1, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 0, ..., 0, 0, 0],\n",
      "        [1, 1, 0, ..., 0, 0, 0],\n",
      "        [1, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=object)\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n",
      "    quantile             float64 8B 0.95\n",
      "Labels before shifting (aligned with future interval):\n",
      "<xarray.DataArray 't2m' (day: 2907, latitude: 33, longitude: 57)> Size: 44MB\n",
      "array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n",
      "    quantile             float64 8B 0.95\n",
      "Labels after shifting (aligned with current day):\n",
      "<xarray.DataArray 't2m' (day: 2901, latitude: 33, longitude: 57)> Size: 44MB\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "...\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
      "Coordinates:\n",
      "    number               int64 8B ...\n",
      "    step                 timedelta64[ns] 8B ...\n",
      "    surface              float64 8B ...\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    valid_time           (day) datetime64[ns] 23kB ...\n",
      "    depthBelowLandLayer  float64 8B ...\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-24\n",
      "    quantile             float64 8B 0.95\n"
     ]
    }
   ],
   "source": [
    "# Define the rolling window size\n",
    "window_size = 7\n",
    "\n",
    "# Step 1: Restrict hot_days to May–July + first days of August\n",
    "hot_days_limited = hot_days.sel(\n",
    "    day=hot_days[\"day\"].dt.month.isin([5, 6, 7]) |\n",
    "         ((hot_days[\"day\"].dt.month == 8) & (hot_days[\"day\"].dt.day <= window_size))\n",
    ")\n",
    "\n",
    "# Count the number of hot days in each rolling window\n",
    "hot_days_rolling = (\n",
    "    hot_days.rolling(day=window_size, center=False)\n",
    "    .construct(\"window_dim\")\n",
    "    .reduce(np.sum, dim=\"window_dim\")\n",
    ")\n",
    "\n",
    "# Create labels: 1 if 3 or more hot days, 0 otherwise\n",
    "labels_next_7_days = (hot_days_rolling >= 3).astype(int)\n",
    "\n",
    "# Align the labels with the dataset (shift back by window_size - 1)\n",
    "labels_next_7_days = labels_next_7_days.shift(day=-(window_size - 1))\n",
    "# Does this makes sense?????\n",
    "\n",
    "# Drop NaN values (caused by shifting)\n",
    "labels_next_7_days = labels_next_7_days.dropna(\"day\")\n",
    "\n",
    "# Debug: Inspect the rolling sum\n",
    "print(\"Rolling sum of hot days over 7-day window:\")\n",
    "print(hot_days_rolling)\n",
    "\n",
    "# Debug: Inspect the labels before and after shifting\n",
    "print(\"Labels before shifting (aligned with future interval):\")\n",
    "print((hot_days_rolling >= 3).astype(int))\n",
    "\n",
    "print(\"Labels after shifting (aligned with current day):\")\n",
    "print(labels_next_7_days)\n",
    "\n",
    "del hot_days, streaks_rolling, streaks_rolling_filled, distinct_streaks, hot_days_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "861239fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable            Type                \n",
      "========================================\n",
      "labels_next_7_days  DataArray           \n",
      "years               ndarray             \n",
      "yearly_data         Dataset             \n",
      "rolling_chunk       Dataset             \n",
      "yearly_labels       DataArray           \n",
      "stacked_features    Dataset             \n",
      "flattened_features  DataArray           \n",
      "X                   ndarray             \n",
      "flattened_labels    DataArray           \n",
      "aligned_labels      DataArray           \n",
      "y                   ndarray             \n",
      "train_years         ndarray             \n",
      "test_years          ndarray             \n",
      "X_train             ndarray             \n",
      "y_train             ndarray             \n",
      "data_summer_merged  Dataset             \n",
      "hot_days_rolling    DataArray           \n",
      "                       types |   # objects |   total size\n",
      "============================ | =========== | ============\n",
      "               numpy.ndarray |         531 |    668.73 MB\n",
      "                       tuple |      608130 |     59.01 MB\n",
      "                        dict |       82821 |     36.15 MB\n",
      "                         str |      222667 |     34.79 MB\n",
      "                        list |      194179 |     26.85 MB\n",
      "                        code |       67027 |     11.47 MB\n",
      "                        type |        7925 |      7.11 MB\n",
      "                         int |      237392 |      6.51 MB\n",
      "                         set |        2326 |      2.19 MB\n",
      "  builtin_function_or_method |       13710 |    963.98 KB\n",
      "                        cell |       24085 |    940.82 KB\n",
      "       weakref.ReferenceType |       12636 |    888.47 KB\n",
      "     collections.OrderedDict |        1258 |    868.61 KB\n",
      "           getset_descriptor |       11473 |    717.06 KB\n",
      "         function (__init__) |        4376 |    615.38 KB\n"
     ]
    }
   ],
   "source": [
    "from pympler import muppy, summary\n",
    "# Filter global variables for numpy arrays and xarray datasets\n",
    "arrays_and_datasets = {\n",
    "    name: type(value).__name__\n",
    "    for name, value in globals().items()\n",
    "    if type(value).__name__ in [\"ndarray\", \"Dataset\", \"DataArray\"]\n",
    "}\n",
    "\n",
    "# Print the results\n",
    "print(f\"{'Variable':<20}{'Type':<20}\")\n",
    "print(\"=\" * 40)\n",
    "for name, var_type in arrays_and_datasets.items():\n",
    "    print(f\"{name:<20}{var_type:<20}\")\n",
    "\n",
    "# Collect all objects in memory\n",
    "all_objects = muppy.get_objects()\n",
    "\n",
    "# Summarize memory usage by type\n",
    "summary.print_(summary.summarize(all_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0125e",
   "metadata": {},
   "source": [
    "## Stacking data of 30 days onto each other and adding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8305e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates:\n",
      "    number               int64 8B 0\n",
      "    step                 timedelta64[ns] 8B 00:00:00\n",
      "    surface              float64 8B 0.0\n",
      "  * latitude             (latitude) float64 264B 44.0 43.75 43.5 ... 36.25 36.0\n",
      "  * longitude            (longitude) float64 456B -10.0 -9.75 -9.5 ... 3.75 4.0\n",
      "    depthBelowLandLayer  float64 8B 0.0\n",
      "  * day                  (day) datetime64[ns] 23kB 2006-05-01 ... 2024-09-30\n"
     ]
    }
   ],
   "source": [
    "print(data_summer_merged.coords)\n",
    "#print(\"Rolling Chunk Days:\")\n",
    "#print(rolling_chunk[\"day\"].values)\n",
    "\n",
    "#print(\"\\nLabels Next 7 Days:\")\n",
    "#print(labels_next_7_days[\"day\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f228d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flattened features (X_train): (176814, 420)\n",
      "Shape of flattened labels (y_train): (176814,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Extract unique years from the 'day' coordinate\n",
    "years = np.unique(data_summer_merged[\"day\"].dt.year)\n",
    "feature_window_size = 30\n",
    "\n",
    "# Directory for saving temporary results\n",
    "processed_dir = \"temp_features_by_year/\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    # Select data for the current year\n",
    "    yearly_data = data_summer_merged.sel(\n",
    "            day=(data_summer_merged[\"day\"].dt.year == year) &\n",
    "                 (data_summer_merged[\"day\"].dt.month.isin([5, 6, 7, 8]))\n",
    "    )\n",
    "    # Create rolling windows\n",
    "    rolling_chunk = (\n",
    "        yearly_data.rolling(day=feature_window_size, center=False)\n",
    "        .construct(\"feature_dim\")\n",
    "        .dropna(\"day\")\n",
    "    )\n",
    "    \n",
    "    # Align features with labels\n",
    "    yearly_labels = labels_next_7_days.sel(day=rolling_chunk[\"day\"])\n",
    "    rolling_chunk, yearly_labels = xr.align(rolling_chunk, yearly_labels, join=\"inner\")\n",
    "    \n",
    "    \n",
    "    stacked_features = rolling_chunk.stack(location=(\"latitude\", \"longitude\"))\n",
    "    flattened_features = stacked_features.to_array(dim=\"variables\").stack(features=(\"variables\", \"feature_dim\")).transpose(\"day\", \"location\", \"features\")\n",
    "    X = flattened_features.values.reshape(flattened_features.shape[0] * flattened_features.shape[1], -1)\n",
    "\n",
    "    # Check the resulting shape\n",
    "    #stacked_labels = yearly_labels.stack(location=(\"latitude\", \"longitude\"))\n",
    "    #flattened_labels = stacked_labels.to_array(dim=\"variables\").stack(features=(\"variables\", \"feature_dim\")).transpose(\"day\", \"location\", \"features\")\n",
    "    #aligned_labels = flattened_labels.sel(day=stacked_features[\"day\"])\n",
    "    #y = aligned_labels.values.flatten()  # Flatten into a single column\n",
    "    \n",
    "    stacked_labels = yearly_labels.stack(location=(\"latitude\", \"longitude\"))\n",
    "    y = stacked_labels.values.flatten()  # Flatten into a single column\n",
    "\n",
    "    # Save to disk\n",
    "    torch.save(torch.tensor(X, dtype=torch.float32), f\"{processed_dir}/features_{year}.pt\")\n",
    "    torch.save(torch.tensor(y, dtype=torch.float32), f\"{processed_dir}/labels_{year}.pt\")\n",
    "    \n",
    "print(\"Shape of flattened features (X_train):\", X.shape)\n",
    "print(\"Shape of flattened labels (y_train):\", y.shape)\n",
    "\n",
    "#del data_summer_merged, hot_days_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7ef4272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024.12.1\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "print(dask.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0b4af",
   "metadata": {},
   "source": [
    "## Train/Test split and flattening the arrays so they can be processed by NN\n",
    "The final array will be 2D. Each record corresponds with one location and one day. This record contains the data of the previous 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b29335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = years[years < 2022]\n",
    "test_years = years[years >= 2022]\n",
    "\n",
    "# Load and train incrementally\n",
    "def load_data_for_year(year):\n",
    "    X = torch.load(f\"{processed_dir}/features_{year}.pt\")\n",
    "    y = torch.load(f\"{processed_dir}/labels_{year}.pt\")    \n",
    "    return X, y\n",
    "\n",
    "# Initialize DataLoader for incremental training\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b6f6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([176814, 420])\n",
      "torch.Size([176814])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data_for_year(2020)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Year 2006 - Loss: 0.0415\n",
      "Year 2007 - Loss: 0.0109\n",
      "Year 2008 - Loss: 0.0006\n",
      "Year 2009 - Loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Train the model\n",
    "class HotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "input_size = 420  # Replace with your feature size\n",
    "model = HotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "global_mean, global_std = None, None  # Compute these during preprocessing if needed\n",
    "\n",
    "for epoch in range(10):  # Adjust the number of epochs\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for year in train_years:\n",
    "        X_train, y_train = load_data_for_year(year)\n",
    "        \n",
    "        # Normalize features\n",
    "        if global_mean is not None and global_std is not None:\n",
    "            X_train = (X_train - global_mean) / global_std\n",
    "        else:\n",
    "            X_train = (X_train - X_train.mean(dim=0)) / X_train.std(dim=0)\n",
    "        # Create DataLoader\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Train the model\n",
    "        total_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(features).squeeze()\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Year {year} - Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aligned_labels_train[\"t2m\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c0dab",
   "metadata": {},
   "source": [
    "### Using different NN and other models to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for year in test_years:\n",
    "    X_test, y_test = load_data_for_year(year)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Normalize features\n",
    "    X_test = (X_test - X_test.mean(dim=0)) / X_test.std(dim=0)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test).squeeze()\n",
    "        all_predictions.append((predictions > 0.5).float().numpy())\n",
    "        all_labels.append(y_test.numpy())\n",
    "\n",
    "# Combine results and evaluate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate = torch.sum(y_train == 1).item() / y_train.size(0)\n",
    "print(f\"Positive rate: {positive_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset and data loader\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class HotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = HotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Initial NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DeeperHotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DeeperHotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = DeeperHotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Deeper NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DropoutHotDayPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DropoutHotDayPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = DropoutHotDayPredictor(input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    for batch in dataloader:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).squeeze()\n",
    "    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), predicted_classes.numpy())\n",
    "precision = precision_score(y_test.numpy(), predicted_classes.numpy())\n",
    "recall = recall_score(y_test.numpy(), predicted_classes.numpy())\n",
    "f1 = f1_score(y_test.numpy(), predicted_classes.numpy())\n",
    "print(\"Dropout NN\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Assuming test_features and test_labels are prepared as PyTorch tensors\n",
    "X_test = flattened_features_test.values.reshape(flattened_features_test.shape[0] * flattened_features_test.shape[1], -1)\n",
    "y_test = aligned_labels_test.values.flatten()  # Flatten into a single column\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_classes = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "precision = precision_score(y_test, predicted_classes)\n",
    "recall = recall_score(y_test, predicted_classes)\n",
    "f1 = f1_score(y_test, predicted_classes)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.data_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
